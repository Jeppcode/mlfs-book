{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "56c1491206486057"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:35:45.499642Z",
     "start_time": "2025-11-11T09:35:45.496733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ],
   "id": "bbc71fdba0734082",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml-lab-py311/bin/python\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:35:45.523444Z",
     "start_time": "2025-11-11T09:35:45.509277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir)\n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH`\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ],
   "id": "b947310a5af18b2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: /Users/niklasdahlbom/Documents/GitHub/mlfs-book\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:35:45.529098Z",
     "start_time": "2025-11-11T09:35:45.527363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "38dd4c5c0740baf0",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model",
   "id": "c869af87e8a1fdce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:41:59.750573Z",
     "start_time": "2025-11-11T09:41:59.480869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Path to your saved model\n",
    "model_path = f\"{root_dir}/notebooks/airquality/air_quality_model/model.json\"\n",
    "\n",
    "# Load the trained model\n",
    "xgb_regressor = XGBRegressor()\n",
    "xgb_regressor.load_model(model_path)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ],
   "id": "daf79ee33439b9f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### City data",
   "id": "a03dc6258f8100ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:35:45.554297Z",
     "start_time": "2025-11-11T09:35:45.551281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_aqicn_sensors():\n",
    "    sensors = []\n",
    "    i = 1\n",
    "    while True:\n",
    "        url = os.getenv(f\"AQICN_URL{i}\")\n",
    "        country = os.getenv(f\"AQICN_COUNTRY{i}\")\n",
    "        city = os.getenv(f\"AQICN_CITY{i}\")\n",
    "        street = os.getenv(f\"AQICN_STREET{i}\")\n",
    "\n",
    "        if not url:\n",
    "            break  # Stop when there is no more AQICN_URL{i} in .env\n",
    "\n",
    "        sensors.append({\n",
    "            \"url\": url,\n",
    "            \"country\": country,\n",
    "            \"city\": city,\n",
    "            \"street\": street\n",
    "        })\n",
    "        i += 1\n",
    "\n",
    "    return sensors\n",
    "\n",
    "# Example usage\n",
    "sensors = get_aqicn_sensors()\n",
    "for s in sensors:\n",
    "    print(s)"
   ],
   "id": "34ac7c389c9f5074",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://api.waqi.info/feed/A71104', 'country': 'Sweden', 'city': 'Borgholm', 'street': 'Norra Långgatan'}\n",
      "{'url': 'https://api.waqi.info/feed/A376954', 'country': 'Sweden', 'city': 'Ljugarn', 'street': 'Storvägen'}\n",
      "{'url': 'https://api.waqi.info/feed/A60076', 'country': 'Sweden', 'city': 'Visby', 'street': 'Östra Tvärgatan'}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:35:45.576312Z",
     "start_time": "2025-11-11T09:35:45.574680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define your CSV files and sensor metadata\n",
    "sensor_files = {\n",
    "    \"Kalmar\": f\"{root_dir}/data/kalmar-air-quality.csv\",\n",
    "    \"VisbyLjugarn\": f\"{root_dir}/data/VisbyLjugarn-air-quality.csv\",\n",
    "    \"VisbyOstraTvargatan\": f\"{root_dir}/data/VisbyOstraTvargatan-air-quality.csv\"\n",
    "}\n",
    "\n",
    "sensor_metadata = {\n",
    "    \"Kalmar\": {\"country\": \"Sweden\", \"city\": \"Kalmar\", \"street\": \"Norra Långgatan\"},\n",
    "    \"VisbyLjugarn\": {\"country\": \"Sweden\", \"city\": \"Gotland\", \"street\": \"Storvägen, Ljugarn\"},\n",
    "    \"VisbyOstraTvargatan\": {\"country\": \"Sweden\", \"city\": \"Gotland\", \"street\": \"Östra Tvärgatan, Visby\"}\n",
    "}"
   ],
   "id": "ae26da3bbe6a2c7c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:35:45.588350Z",
     "start_time": "2025-11-11T09:35:45.586501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_process_sensor(csv_file, metadata):\n",
    "    util.check_file_path(csv_file)  # Ensure file exists\n",
    "    df = pd.read_csv(csv_file, parse_dates=['date'], skipinitialspace=True)\n",
    "\n",
    "    # Rename PM2.5 column\n",
    "    if 'median' in df.columns:\n",
    "        df.rename(columns={'median': 'pm25'}, inplace=True)\n",
    "\n",
    "    # Sort and create lag features\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    for lag in range(1, 4):\n",
    "        df[f'pm25_lag_{lag}'] = df['pm25'].shift(lag)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # Add sensor metadata\n",
    "    df['country'] = metadata['country']\n",
    "    df['city'] = metadata['city']\n",
    "    df['street'] = metadata['street']\n",
    "\n",
    "    return df\n"
   ],
   "id": "2bff13b69e7cb4e7",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:35:48.103782Z",
     "start_time": "2025-11-11T09:35:48.065864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process all sensors\n",
    "sensor_dfs = {}\n",
    "for name, csv_file in sensor_files.items():\n",
    "    sensor_dfs[name] = load_and_process_sensor(csv_file, sensor_metadata[name])\n",
    "\n",
    "# Optional: Combine all sensors into one DataFrame\n",
    "df_features = pd.concat(sensor_dfs.values(), ignore_index=True)\n",
    "df_features = df_features.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "df_features.head()"
   ],
   "id": "678c827d3d0ffd80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully found at the path: /Users/niklasdahlbom/Documents/GitHub/mlfs-book/data/kalmar-air-quality.csv\n",
      "File successfully found at the path: /Users/niklasdahlbom/Documents/GitHub/mlfs-book/data/VisbyLjugarn-air-quality.csv\n",
      "File successfully found at the path: /Users/niklasdahlbom/Documents/GitHub/mlfs-book/data/VisbyOstraTvargatan-air-quality.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                       date   min    max  pm25    q1    q3  stdev  count  \\\n",
       "0 2019-12-09 00:00:00+00:00  1.60   3.16  2.29  2.12  2.54  0.317    310   \n",
       "1 2019-12-09 00:00:00+00:00  1.76   5.24  2.41  2.15  2.82  0.517    315   \n",
       "2 2019-12-10 00:00:00+00:00  0.40  17.10  1.38  0.97  2.16  2.209    387   \n",
       "3 2019-12-10 00:00:00+00:00  0.57   5.85  1.10  0.85  1.86  0.811    387   \n",
       "4 2019-12-11 00:00:00+00:00  1.30   7.00  2.86  2.50  3.34  0.887    423   \n",
       "\n",
       "   pm25_lag_1  pm25_lag_2  pm25_lag_3 country     city                  street  \n",
       "0        0.00        0.00         0.0  Sweden   Kalmar         Norra Långgatan  \n",
       "1        0.00        0.00         0.0  Sweden  Gotland  Östra Tvärgatan, Visby  \n",
       "2        2.41        0.00         0.0  Sweden  Gotland  Östra Tvärgatan, Visby  \n",
       "3        2.29        0.00         0.0  Sweden   Kalmar         Norra Långgatan  \n",
       "4        1.10        2.29         0.0  Sweden   Kalmar         Norra Långgatan  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>pm25</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "      <th>stdev</th>\n",
       "      <th>count</th>\n",
       "      <th>pm25_lag_1</th>\n",
       "      <th>pm25_lag_2</th>\n",
       "      <th>pm25_lag_3</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-09 00:00:00+00:00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.317</td>\n",
       "      <td>310</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Kalmar</td>\n",
       "      <td>Norra Långgatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-09 00:00:00+00:00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>5.24</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.517</td>\n",
       "      <td>315</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Gotland</td>\n",
       "      <td>Östra Tvärgatan, Visby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-10 00:00:00+00:00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>17.10</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.209</td>\n",
       "      <td>387</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Gotland</td>\n",
       "      <td>Östra Tvärgatan, Visby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-10 00:00:00+00:00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.811</td>\n",
       "      <td>387</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Kalmar</td>\n",
       "      <td>Norra Långgatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-11 00:00:00+00:00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.887</td>\n",
       "      <td>423</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Kalmar</td>\n",
       "      <td>Norra Långgatan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:40:46.473122Z",
     "start_time": "2025-11-11T09:40:46.441859Z"
    }
   },
   "cell_type": "code",
   "source": "df_features.to_csv(f\"{root_dir}/data/all_station_features.csv\", index=False)",
   "id": "d9f737e7551a1dfb",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_station_features(station_name, weather_df, pm25_init=[0,0,0]):\n",
    "    \"\"\"\n",
    "    Build a feature DataFrame for a single station.\n",
    "\n",
    "    Parameters:\n",
    "    - station_name: str, name of the station\n",
    "    - weather_df: pd.DataFrame with columns ['date', 'temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max', 'wind_direction_10m_dominant']\n",
    "    - pm25_init: list of 3 floats, initial PM2.5 lag values [lag_1, lag_2, lag_3]\n",
    "\n",
    "    Returns:\n",
    "    - df_pred: pd.DataFrame ready for prediction\n",
    "    \"\"\"\n",
    "    df_pred = weather_df.copy()\n",
    "\n",
    "    # Ensure datetime type and remove timezone if present\n",
    "    df_pred['date'] = pd.to_datetime(df_pred['date']).dt.tz_localize(None)\n",
    "\n",
    "    # Add lag features\n",
    "    df_pred['pm25_lag_1'] = pm25_init[0]\n",
    "    df_pred['pm25_lag_2'] = pm25_init[1]\n",
    "    df_pred['pm25_lag_3'] = pm25_init[2]\n",
    "\n",
    "    # Add station identifier\n",
    "    df_pred['city'] = station_name\n",
    "\n",
    "    return df_pred"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_pm25(df_pred, model):\n",
    "    \"\"\"\n",
    "    Fill 'pm25_predicted' column using rolling lag features.\n",
    "\n",
    "    Parameters:\n",
    "    - df_pred: pd.DataFrame with feature columns and initial lag values\n",
    "    - model: trained XGBoost or sklearn regressor\n",
    "\n",
    "    Returns:\n",
    "    - df_pred with 'pm25_predicted' column filled\n",
    "    \"\"\"\n",
    "    df_pred = df_pred.copy()\n",
    "    df_pred['pm25_predicted'] = 0.0\n",
    "\n",
    "    for i in range(len(df_pred)):\n",
    "        # Prepare features for prediction\n",
    "        X = df_pred.loc[i, ['temperature_2m_mean', 'precipitation_sum',\n",
    "                            'wind_speed_10m_max', 'wind_direction_10m_dominant',\n",
    "                            'pm25_lag_1', 'pm25_lag_2', 'pm25_lag_3']].values.reshape(1, -1)\n",
    "\n",
    "        # Predict\n",
    "        pred = model.predict(X)[0]\n",
    "        df_pred.loc[i, 'pm25_predicted'] = pred\n",
    "\n",
    "        # Update lag features for next row\n",
    "        if i + 1 < len(df_pred):\n",
    "            df_pred.loc[i+1, 'pm25_lag_1'] = pred\n",
    "        if i + 2 < len(df_pred):\n",
    "            df_pred.loc[i+2, 'pm25_lag_2'] = pred\n",
    "        if i + 3 < len(df_pred):\n",
    "            df_pred.loc[i+3, 'pm25_lag_3'] = pred\n",
    "\n",
    "    return df_pred"
   ],
   "id": "d9ccf7d95cde5065"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_multiple_stations(stations, weather_dict, model):\n",
    "    \"\"\"\n",
    "    Run PM2.5 prediction for multiple stations.\n",
    "\n",
    "    Parameters:\n",
    "    - stations: list of dicts with keys ['name', 'init_lags']\n",
    "    - weather_dict: dict mapping station_name -> weather_df\n",
    "    - model: trained XGBoost model\n",
    "\n",
    "    Returns:\n",
    "    - combined pd.DataFrame for all stations\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    for s in stations:\n",
    "        weather_df = weather_dict[s['name']]\n",
    "        df_pred = prepare_station_features(s['name'], weather_df, s['init_lags'])\n",
    "        df_pred = predict_pm25(df_pred, model)\n",
    "        all_predictions.append(df_pred)\n",
    "\n",
    "    final_df = pd.concat(all_predictions, ignore_index=True)\n",
    "    return final_df"
   ],
   "id": "c5d6f16d4b924d27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_predictions = predict_multiple_stations(stations, weather_dict, xgb_regressor)\n",
    "\n",
    "# Check results\n",
    "print(all_predictions.head())"
   ],
   "id": "aeed5f02d1d2ddfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (ml-lab)",
   "language": "python",
   "name": "ml-lab-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
